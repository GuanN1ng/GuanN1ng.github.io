---
layout: post 
title:  Kafka 分区状态机与副本状态机
date:   2021-11-06 22:17:56 
categories: Kafka
---

[Kafka Topic生命周期](https://guann1ng.github.io/kafka/2021/10/21/Kafka-Topic%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/) 的源码分析中，无论是Topic的创建、扩容还是删除均是通过
PartitionStateMachine与ReplicaStateMachine完成分区与副本状态的流转。本篇内容将对PartitionStateMachine与ReplicaStateMachine的源码进行分析。

**Broker成功当选为集群Controller后**，会先调用initializeControllerContext()方法，从ZK中读取当前集群中所有的Topic信息，包括Topic的分区和副本信息，然后进行分区与副本的状态初始化，分为两步：

* replicaStateMachine.startup()，启动副本状态机，初始化所有副本状态；
* partitionStateMachine.startup()，启动分区状态机，初始化所有分区状态；

```
private def onControllerFailover(): Unit = {
  ...//other code
  //读取ZK中节点信息 
  initializeControllerContext()

  // We need to send UpdateMetadataRequest after the controller context is initialized and before the state machines
  // are started. The is because brokers need to receive the list of live brokers from UpdateMetadataRequest before
  // they can process the LeaderAndIsrRequests that are generated by replicaStateMachine.startup() and
  // partitionStateMachine.startup().
  sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq, Set.empty)
  //启动副本状态机
  replicaStateMachine.startup()
  //启动分区状态机
  partitionStateMachine.startup()
  
  ...//otherCode

}
```


# ReplicaStateMachine

ReplicaStateMachine负责处理Kafka集群中所有副本的状态流转，并定义了Replica可能处于的7种状态，详情如下：

* **NewReplica**：新建Replica的初始状态，此状态的Replica仅可作为分区的follower副本，有效前置状态(上一个状态)是NonExistentReplica；

* **OnlineReplica**：对应的Partition状态为OnlinePartition后，副本状态从NewReplica流转为OnlineReplica，此状态的Replica即可作为Leader也可作为follower,有效前置状态包括NewReplica，OnlineReplica，OfflineReplica和ReplicaDeletionIneligible；

* **OfflineReplica**：副本离线状态，如持有副本的Broker宕机或收到StopReplicaRequest(deletion=false)。有效前置状态包括NewReplica，OnlineReplica，OfflineReplica和ReplicaDeletionIneligible；

* **ReplicaDeletionStarted**：副本收到StopReplicaRequest(deletion=true)请求，开始执行副本删除时的状态，有效前置状态为OfflineReplica；

* **ReplicaDeletionSuccessful**：副本删除成功(StopReplicaResponse.error==Errors.NONE)后的状态，有效前置状态为ReplicaDeletionStarted；

* **ReplicaDeletionIneligible**：副本删除失败(StopReplicaResponse.error!=Errors.NONE)后的状态，有效前置状态为OfflineReplica和ReplicaDeletionStarted；

* **NonExistentReplica**：副本成功删除的最后状态，有效前置状态为ReplicaDeletionSuccessful；

## startup

ReplicaStateMachine#startup()方法源码如下：

```
//Invoked on successful controller election.
def startup(): Unit = {
  //初始化副本状态
  initializeReplicaState()
  //副本分类  在线副本 离线副本
  val (onlineReplicas, offlineReplicas) = controllerContext.onlineAndOfflineReplicas
  //进行状态变更
  handleStateChanges(onlineReplicas.toSeq, OnlineReplica)
  handleStateChanges(offlineReplicas.toSeq, OfflineReplica)
}
```

Broker当选为Controller后，ReplicaStateMachine需要完成的工作可分为两步：

* 初始化所有副本的状态；
* 将副本分类为onlineReplicas和offlineReplicas，调用handleStateChanges()方法执行相应的状态转换。

### initializeReplicaState

initializeReplicaState()方法源码如下：

```
private def initializeReplicaState(): Unit = {
  controllerContext.allPartitions.foreach { partition =>
    val replicas = controllerContext.partitionReplicaAssignment(partition)
    replicas.foreach { replicaId =>
      //遍历所有的分区副本
      val partitionAndReplica = PartitionAndReplica(partition, replicaId)
      if (controllerContext.isReplicaOnline(replicaId, partition)) {
        //副本在线的状态设置为OnlineReplica
        controllerContext.putReplicaState(partitionAndReplica, OnlineReplica)
      } else {
        // mark replicas on dead brokers as failed for topic deletion, if they belong to a topic to be deleted.
        // This is required during controller failover since during controller failover a broker can go down,
        // so the replicas on that broker should be moved to ReplicaDeletionIneligible to be on the safer side.
        //否则设置为ReplicaDeletionIneligible
        controllerContext.putReplicaState(partitionAndReplica, ReplicaDeletionIneligible)
      }
    }
  }
}

//副本是否在线判断
def isReplicaOnline(brokerId: Int, topicPartition: TopicPartition, includeShuttingDownBrokers: Boolean = false): Boolean = {
  val brokerOnline = {
    if (includeShuttingDownBrokers) liveOrShuttingDownBrokerIds.contains(brokerId)
    else liveBrokerIds.contains(brokerId)
  }
  //broker节点在线 且 分区日志未离线（对应的日志目录未脱机）
  brokerOnline && !replicasOnOfflineDirs.getOrElse(brokerId, Set.empty).contains(topicPartition)
}
```

initializeReplicaState()方法中，会为所有的Replica设置初始状态(更新ControllerContext缓存)，此时仅存在两种状态：若副本在线则将状态设置为OnlineReplica，否则设置为ReplicaDeletionIneligible。

## handleStateChanges

ZkReplicaStateMachine#handleStateChanges()是副本状态机的核心方法，负责副本状态流转的实现。源码如下:

```
override def handleStateChanges(replicas: Seq[PartitionAndReplica],
                            //目标状态 
                            targetState: ReplicaState): Unit = {
  if (replicas.nonEmpty) {
    try {
      //创建Controller请求发送批次
      controllerBrokerRequestBatch.newBatch()
        //执行状态变更
        doHandleStateChanges(replicaId, replicas, targetState)
      }
      //将处理状态流转过程中创建的请求发送给目标Broker
      controllerBrokerRequestBatch.sendRequestsToBrokers(controllerContext.epoch)
    } catch {
      ...// error
    }
  }
}
```

执行副本状态变更的是方法ZkReplicaStateMachine#handleStateChanges()，实现如下：

```
private def doHandleStateChanges(replicaId: Int, replicas: Seq[PartitionAndReplica], targetState: ReplicaState): Unit = {
  val stateLogger = stateChangeLogger.withControllerEpoch(controllerContext.epoch)
  val traceEnabled = stateLogger.isTraceEnabled
  //新建Replica或已删除的Replica初始化状态为NonExistentReplica
  replicas.foreach(replica => controllerContext.putReplicaStateIfNotExists(replica, NonExistentReplica))
  //检查副本当前状态是否为目标状态的前置有效状态
  val (validReplicas, invalidReplicas) = controllerContext.checkValidReplicaStateChange(replicas, targetState)
  invalidReplicas.foreach(replica => logInvalidTransition(replica, targetState))

  targetState match {
    case NewReplica => ...//
    case OnlineReplica => ...//
    case OfflineReplica => ...//
    case ReplicaDeletionStarted => ...//
    case ReplicaDeletionIneligible => ...//
    case ReplicaDeletionSuccessful => ...//
    case NonExistentReplica => ...//
  }
}
```
handleStateChanges()方法按照目标状态共分为了7个分支，下面分别进行分析。

### NewReplica

新建Replica共有两种情况：新建分区或修改现有分区的副本数量：

* Replica对应的分区**没有leaderAndIsr信息**，即**新建分区**，将Replica状态修改为NewReplica，结束流程；
* Replica对应的分区**有leaderAndIsr信息**，即**现有分区增加副本数量**，需要向Replica所在Broker节点发送LeaderAndIsrRequest及向所有Broker发送UpdateMetadataRequest，最后将Replica状态修改为NewReplica，结束流程。

源码如下：

```
case NewReplica =>
  validReplicas.foreach { replica =>
    val partition = replica.topicPartition
    val currentState = controllerContext.replicaState(replica)
    //获取分区的Leader ISR信息
    controllerContext.partitionLeadershipInfo(partition) match {
      case Some(leaderIsrAndControllerEpoch) =>
        if (leaderIsrAndControllerEpoch.leaderAndIsr.leader == replicaId) {
          //执行状态变更的是Leader副本，抛出异常，Leader副本不能处于NewReplica状态
          val exception = new StateChangeFailedException(s"Replica $replicaId for partition $partition cannot be moved to NewReplica state as it is being requested to become leader")
          logFailedStateChange(replica, currentState, OfflineReplica, exception)
        } else {
          //向Replica所在Broker节点发送LeaderAndIsrRequest 以及  向所有Broker发送UpdateMetadataRequest
          controllerBrokerRequestBatch.addLeaderAndIsrRequestForBrokers(Seq(replicaId),replica.topicPartition,leaderIsrAndControllerEpoch,controllerContext.partitionFullReplicaAssignment(replica.topicPartition),isNew = true)
          //更新缓存状态
          controllerContext.putReplicaState(replica, NewReplica)
        }
      case None =>
        //更新缓存状态
        controllerContext.putReplicaState(replica, NewReplica)
    }
  }
```

### OnlineReplica

OnlineReplica状态的**前置有效状态包括NewReplica，OnlineReplica，OfflineReplica和ReplicaDeletionIneligible**4种。可分为两类：

* 新建Replica，即现状态为NewReplica状态，若Replica不存在于分区AR集合中，则添加并更新，因新建Replica转为NewReplica状态时已发送过LeaderAndIsrRequest和UpdateMetadataRequest请求，此处不再执行；
* 旧有Replica重新上线，即现状态为OnlineReplica，OfflineReplica和ReplicaDeletionIneligible状态，需要向目标Broker发送LeaderAndIsrRequest和UpdateMetadataRequest请求。

最后完成缓存状态更新。

```
case OnlineReplica =>
  validReplicas.foreach { replica =>
    val partition = replica.topicPartition
    val currentState = controllerContext.replicaState(replica)

    currentState match {
      //副本当前状态为 NewReplica
      case NewReplica =>
        //获取分区副本集合AR
        val assignment = controllerContext.partitionFullReplicaAssignment(partition)
        if (!assignment.replicas.contains(replicaId)) {
          error(s"Adding replica ($replicaId) that is not part of the assignment $assignment")
          //将新副本添加到AR集合中，并更新
          val newAssignment = assignment.copy(replicas = assignment.replicas :+ replicaId)
          controllerContext.updatePartitionFullReplicaAssignment(partition, newAssignment)
        }
      case _ =>
        controllerContext.partitionLeadershipInfo(partition) match {
          case Some(leaderIsrAndControllerEpoch) =>
            //存在分区leader isr信息 向Replica所在Broker节点发送LeaderAndIsrRequest 以及  向所有Broker发送UpdateMetadataRequest
            controllerBrokerRequestBatch.addLeaderAndIsrRequestForBrokers(Seq(replicaId),replica.topicPartition,leaderIsrAndControllerEpoch,controllerContext.partitionFullReplicaAssignment(partition), isNew = false)
          case None =>
        }
    }
    //缓存状态更新
    controllerContext.putReplicaState(replica, OnlineReplica)
  }
```


### OfflineReplica

OfflineReplica表示副本已下线，流程分为三步：

* 向副本节点发送StopReplicaRequest(deletePartition=false)，停止副本进行同步；
* 下线的副本分区有leader和ISR信息，将副本从ISR集合移除(有ZK节点操作)，若Topic非待删除Topic，发送LeaderAndIsrRequest及UpdateMetadataRequest，通知其他副本分区ISR集合变动；
* 下线的副本分区没有leader和ISR信息，发送UpdateMetadataRequest并更新缓存状态。

源码如下：

```
case OfflineReplica =>
  validReplicas.foreach { replica =>
    //向副本Broker发送StopReplicaRequest 停止副本同步
    controllerBrokerRequestBatch.addStopReplicaRequestForBrokers(Seq(replicaId), replica.topicPartition, deletePartition = false)
  }
  val (replicasWithLeadershipInfo, replicasWithoutLeadershipInfo) = validReplicas.partition { replica =>
    controllerContext.partitionLeadershipInfo(replica.topicPartition).isDefined
  }
  //副本分区有leader ISR信息的，将副本从ISR集合中移除
  val updatedLeaderIsrAndControllerEpochs = removeReplicasFromIsr(replicaId, replicasWithLeadershipInfo.map(_.topicPartition))
  updatedLeaderIsrAndControllerEpochs.forKeyValue { (partition, leaderIsrAndControllerEpoch) =>
    stateLogger.info(s"Partition $partition state changed to $leaderIsrAndControllerEpoch after removing replica $replicaId from the ISR as part of transition to $OfflineReplica")
    if (!controllerContext.isTopicQueuedUpForDeletion(partition.topic)) {
      //Topic 非待删除Topic
      val recipients = controllerContext.partitionReplicaAssignment(partition).filterNot(_ == replicaId)
      //发送 LeaderAndIsrRequest 请求给剩余的其他副本,ISR发生变化
      controllerBrokerRequestBatch.addLeaderAndIsrRequestForBrokers(recipients,partition,leaderIsrAndControllerEpoch,controllerContext.partitionFullReplicaAssignment(partition), isNew = false)
    }
    //更新状态
    val replica = PartitionAndReplica(partition, replicaId)
    controllerContext.putReplicaState(replica, OfflineReplica)
  }
  
  replicasWithoutLeadershipInfo.foreach { replica =>
    //发送UpdateMetadataRequest 并更新缓存状态
    controllerBrokerRequestBatch.addUpdateMetadataRequestForBrokers(controllerContext.liveOrShuttingDownBrokerIds.toSeq, Set(replica.topicPartition))
    controllerContext.putReplicaState(replica, OfflineReplica)
  }
```


### ReplicaDeletionStarted

ReplicaDeletionStarted状态表示开始删除Replica，前置有效状态为OfflineReplica，即只有OfflineReplica才可以进行删除。此时需要向Replica所在Broker发送
StopReplicaRequest(deletePartition=true)请求，目标Broker收到请求后，开始执行删除操作，操作结束后返回StopReplicaResponse。

源码如下：

```
case ReplicaDeletionStarted =>
  validReplicas.foreach { replica =>
    ...// log
    //更新副本状态
    controllerContext.putReplicaState(replica, ReplicaDeletionStarted)
    //向Replica节点发送StopReplicaRequest，执行副本删除
    controllerBrokerRequestBatch.addStopReplicaRequestForBrokers(Seq(replicaId), replica.topicPartition, deletePartition = true)
  }
```

### ReplicaDeletionIneligible

当Controller收到的StopReplicaResponse.error!=Errors.NONE，Replica删除失败，状态会被更新为ReplicaDeletionIneligible，分区流转到此状太时，只需将ControllerContext中的缓存更新即可。

```
case ReplicaDeletionIneligible =>
  validReplicas.foreach { replica =>
    ...// log
    //更新缓存状态
    controllerContext.putReplicaState(replica, ReplicaDeletionIneligible)
  }
```

### ReplicaDeletionSuccessful

当Controller收到的StopReplicaResponse.error==Errors.NONE，Replica删除完成，状态会被更新为ReplicaDeletionSuccessful，分区流转到此状太时，只需将ControllerContext中的缓存更新即可。

```
case ReplicaDeletionSuccessful =>
  validReplicas.foreach { replica =>
     ...// log 日志
    //更新缓存状态
    controllerContext.putReplicaState(replica, ReplicaDeletionSuccessful)
  }
```

### NonExistentReplica

仅当Replica成功删除后，才会流转到NonExistentReplica状态。此时需要清理两种副本信息缓存：

* 分区的副本集合信息，存储于ControllerContext#partitionAssignments(`mutable.Map.empty[String, mutable.Map[Int, ReplicaAssignment]]`)集合中；
* 副本的状态缓存，存储于ControllerContext#replicaStates(`mutable.Map.empty[PartitionAndReplica, ReplicaState]`)中。

```
case NonExistentReplica =>
  validReplicas.foreach { replica =>
    //从分区的所有副本集合中移除该副本
    val newAssignedReplicas = controllerContext
      .partitionFullReplicaAssignment(replica.topicPartition)
      .removeReplica(replica.replica)
    //更新分区的副本集合  
    controllerContext.updatePartitionFullReplicaAssignment(replica.topicPartition, newAssignedReplicas)
    //移除副本的状态缓存
    controllerContext.removeReplicaState(replica)
  }
```


# PartitionStateMachine

PartitionStateMachine对象负责处理Kafka集群中所有主题分区状态的转换，并定义了Partition可能处于的所有状态。分区状态共有4种：

* **NonExistentPartition**：Partition之前未被创建或者创建后又被删除了，此状态的有效前置状态是OfflinePartition；
* **NewPartition**：Partition创建后的初始状态，此状态下的Partition还没有Leader副本和ISR信息，有效前置状态是NonExistentPartition；
* **OnlinePartition**：完成Partition的Leader副本选举及ISR信息后，分区状态将流转为OnlinePartition，有效前置状态是NewPartition、OnlinePartition或OfflinePartition；
* **OfflinePartition**：当Partition的Leader副本副本掉线或删除分区Topic时，分区状态将流转为OfflinePartition，有效前置状态是NewPartition、OnlinePartition或OfflinePartition。


## startup

PartitionStateMachine#startup()方法源码如下：

```
// Invoked on successful controller election.
def startup(): Unit = {
  //初始化分区状态
  initializePartitionState()
  //副本leader选举
  triggerOnlinePartitionStateChange()
}
```

Broker当选为Controller后，PartitionStateMachine需要完成的工作分为两部分：1、初始化集群内所有分区的状态；2、触发OfflinePartition，NewPartition分区leader选举。

### initializePartitionState

initializePartitionState()会遍历所有ControllerContext中所有的分区(当选为Controller后从ZK中读取并缓存)，并为其设置状态：

* Partition没有LeaderAndIsr信息，将分区状态设置为NewPartition；
* Partition有LeaderAndIsr信息：
  * Leader副本在线的，分区状态设置为OnlinePartition；
  * Leader副本离线的，分区状态设置为OfflinePartition；

```
private def initializePartitionState(): Unit = {
  for (topicPartition <- controllerContext.allPartitions) {
    // check if leader and isr path exists for partition. If not, then it is in NEW state
    //检查分区是否存在leader和isr信息
    controllerContext.partitionLeadershipInfo(topicPartition) match {
      case Some(currentLeaderIsrAndEpoch) =>
        // check if the leader for partition is alive. If yes, it is in Online state, else it is in Offline state
        if (controllerContext.isReplicaOnline(currentLeaderIsrAndEpoch.leaderAndIsr.leader, topicPartition))
        // leader is alive
          controllerContext.putPartitionState(topicPartition, OnlinePartition)
        else
          controllerContext.putPartitionState(topicPartition, OfflinePartition)
      case None =>
        controllerContext.putPartitionState(topicPartition, NewPartition)
    }
  }
}
```

### triggerOnlinePartitionStateChange

完成分区状态初始化后，调用triggerOnlinePartitionStateChange()方法为所有状态为OfflinePartition或NewPartition的触发一次分区副本Leader选举，若选举成功，则将分区状态更新为
OnlinePartition。选举策略为OfflinePartitionLeaderElectionStrategy。源码如下：

```
def triggerOnlinePartitionStateChange(): Map[TopicPartition, Either[Throwable, LeaderAndIsr]] = {
  //获取所有OfflinePartition, NewPartition状态的分区
  val partitions = controllerContext.partitionsInStates(Set(OfflinePartition, NewPartition))
  triggerOnlineStateChangeForPartitions(partitions)
}

private def triggerOnlineStateChangeForPartitions(partitions: collection.Set[TopicPartition]): Map[TopicPartition, Either[Throwable, LeaderAndIsr]] = {
  // try to move all partitions in NewPartition or OfflinePartition state to OnlinePartition state except partitions
  // that belong to topics to be deleted
  val partitionsToTrigger = partitions.filter { partition =>
    //过滤待删除的Topic
    !controllerContext.isTopicQueuedUpForDeletion(partition.topic)
  }.toSeq
  //进行状态变更及使用OfflinePartitionLeaderElectionStrategy策略进行leader选举
  handleStateChanges(partitionsToTrigger, OnlinePartition, Some(OfflinePartitionLeaderElectionStrategy(false)))
}
```

## handleStateChanges

ZkPartitionStateMachine#handleStateChanges()方法是分区状态机的核心方法，负责分区状态流转的实现，且如有需要，使用传入的分区副本Leader选举策略PartitionLeaderElectionStrategy完成Leader选举。源码如下：

```
  override def handleStateChanges(
    partitions: Seq[TopicPartition], //待变更状态的分区
    targetState: PartitionState, // 目标状态
    partitionLeaderElectionStrategyOpt: Option[PartitionLeaderElectionStrategy] //可选参数，副本leader选举策略
  ): Map[TopicPartition, Either[Throwable, LeaderAndIsr]] = {
    if (partitions.nonEmpty) {
      try {
        //创建批量请求
        controllerBrokerRequestBatch.newBatch()
        //执行状态转移及leader选举
        val result = doHandleStateChanges( partitions, targetState, partitionLeaderElectionStrategyOpt)
        //发送分区变更状态时创建爱的相关请求(LeaderAndIsr 请求和 UpdateMetadata)给所有的broker
        controllerBrokerRequestBatch.sendRequestsToBrokers(controllerContext.epoch)
        result
      } catch {
        ...// error
      }
    } else {
      Map.empty
    }
  }
```

执行分区状态变更的是方法ZkPartitionStateMachine#doHandleStateChanges()，实现如下：

```
private def doHandleStateChanges(
  partitions: Seq[TopicPartition],
  targetState: PartitionState,
  partitionLeaderElectionStrategyOpt: Option[PartitionLeaderElectionStrategy]
): Map[TopicPartition, Either[Throwable, LeaderAndIsr]] = {
  val stateChangeLog = stateChangeLogger.withControllerEpoch(controllerContext.epoch)
  val traceEnabled = stateChangeLog.isTraceEnabled
  //分区不存在，则初始化为NonExistentPartition状态
  partitions.foreach(partition => controllerContext.putPartitionStateIfNotExists(partition, NonExistentPartition))
  //检查分区当前状态是否为目标状态的有效前置状态
  val (validPartitions, invalidPartitions) = controllerContext.checkValidPartitionStateChange(partitions, targetState)
  invalidPartitions.foreach(partition => logInvalidTransition(partition, targetState))

  targetState match {
    case NewPartition =>
      ...// 
    case OnlinePartition =>
      ...//
    case OfflinePartition | NonExistentPartition =>
      ...//
  }
}
```

doHandleStateChanges()方法中根据不同的目标状态逻辑处理共分为3个分支：分别为：NewPartition，OnlinePartition，OfflinePartition或NonExistentPartition。

### NewPartition

当分区目标状态为NewPartition，有效前置状态是NonExistentPartition，即此时正在创建分区(创建主题或分区扩容)，分区状态机只需完成ControllerContext缓存更新即可。

```
case NewPartition =>
  validPartitions.foreach { partition =>
    stateChangeLog.info(s"Changed partition $partition state from ${partitionState(partition)} to $targetState with assigned replicas ${controllerContext.partitionReplicaAssignment(partition).mkString(",")}")
    controllerContext.putPartitionState(partition, NewPartition)
  }
  Map.empty
```

### OnlinePartition

当分区目标状态为OnlinePartition，此时共分为两种情况：

* 当前分区状态为NewPartition，此时需要为新建分区完成leader及ISR初始化并更新ControllerContext缓存中的副本状态，Leader为所有onlineReplica列表的第一个，ISR为全部onlineReplica。initializeLeaderAndIsrForPartitions()方法的源码分析可见[Kafka Topic生命周期](https://guann1ng.github.io/kafka/2021/10/21/Kafka-Topic%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/) ,此处不再复述。
* 当前分区状态为OfflinePartition或OnlinePartition，通过指定的分区leader副本选举策略(若无抛出异常)进行选举，选举成功后，更新ControllerContext缓存中的副本状态。

上述两种情况，本质均是完成分区Leader副本的选举，选举成功后，都会触发向分区所有Replica发送LeaderAndIsr请求。具体的选举策略见下方。

```
case OnlinePartition =>
  //当前状态为NewPartition的分区
  val uninitializedPartitions = validPartitions.filter(partition => partitionState(partition) == NewPartition)
  //当前状态为OfflinePartition或OnlinePartition的分区
  val partitionsToElectLeader = validPartitions.filter(partition => partitionState(partition) == OfflinePartition || partitionState(partition) == OnlinePartition)
  if (uninitializedPartitions.nonEmpty) {
    //为状态为NewPartition的分区初始化leader 及 ISR信息，初始化成功后更新状态为OnlinePartition
    val successfulInitializations = initializeLeaderAndIsrForPartitions(uninitializedPartitions)
    successfulInitializations.foreach { partition =>
      controllerContext.putPartitionState(partition, OnlinePartition)
    }
  }
  if (partitionsToElectLeader.nonEmpty) {
    //当前状态为OfflinePartition或OnlinePartition的分区，进行leader选举
    val electionResults = electLeaderForPartitions( partitionsToElectLeader,
      //未设置选举策略抛出异常
      partitionLeaderElectionStrategyOpt.getOrElse( throw new IllegalArgumentException("Election strategy is a required field when the target state is OnlinePartition"))
    )

    electionResults.foreach {
      case (partition, Right(leaderAndIsr)) =>
        stateChangeLog.info(
          s"Changed partition $partition from ${partitionState(partition)} to $targetState with state $leaderAndIsr"
        )
        //选举成功，更新状态为OnlinePartition
        controllerContext.putPartitionState(partition, OnlinePartition)
      case (_, Left(_)) => // Ignore; no need to update partition state on election error
    }

    electionResults
  } else {
    Map.empty
  }
```


### OfflinePartition | NonExistentPartition

当分区目标状态为OfflinePartition或NonExistentPartition，分区状态机只需完成ControllerContext缓存更新即可。

```
case OfflinePartition | NonExistentPartition =>
  validPartitions.foreach { partition =>
    if (traceEnabled) stateChangeLog.trace(s"Changed partition $partition state from ${partitionState(partition)} to $targetState")
    controllerContext.putPartitionState(partition, targetState)
  }
  Map.empty
```


## 分区Leader副本选举

分区状态机中共定义了4中选举策略：

| 策略  | 执行方法                                                               | 作用                              |
|-----|--------------------------------------------------------------------|---------------------------------|
| OfflinePartitionLeaderElectionStrategy  | PartitionLeaderElectionAlgorithms#offlinePartitionLeaderElection() | 创建分区(创建主题或分库扩容)或分区原先Leader下线时使用 |
| ReassignPartitionLeaderElectionStrategy  | PartitionLeaderElectionAlgorithms#reassignPartitionLeaderElection()                                      | 对分区副本重新分配后使用                    |
| PreferredReplicaPartitionLeaderElectionStrategy  | PartitionLeaderElectionAlgorithms#preferredReplicaPartitionLeaderElection()                              | 最优Leader选举，手动触发或自动Leader均衡调度时使用 |
| ControlledShutdownPartitionLeaderElectionStrategy  | PartitionLeaderElectionAlgorithms#controlledShutdownPartitionLeaderElection()                            | 当前Controller节点Shutdown时使用       |


### OfflinePartitionLeaderElectionStrategy

创建分区(创建主题或分库扩容)或分区原先Leader下线，分区需要选举一个新的Leader副本，此时选用的选举策略为OfflinePartitionLeaderElectionStrategy。对应算法实现如下：

```
def offlinePartitionLeaderElection(assignment: Seq[Int],  //分区所有副本 AR集合
                                isr: Seq[Int],   //分区ISR集合
                                liveReplicas: Set[Int],   //在线Replica集合
                                uncleanLeaderElectionEnabled: Boolean, //是否允许非ISR副本当选为Leader 
                                controllerContext: ControllerContext): Option[Int] = {
  //遍历AR 查找第一个在线且在ISR集合中的副本作为Leader
  assignment.find(id => liveReplicas.contains(id) && isr.contains(id)).orElse {
    //若上一步未找到 且  unclean.leader.election.enable配置为true
    if (uncleanLeaderElectionEnabled) {
      //遍历AR 查找第一个在线副本
      val leaderOpt = assignment.find(liveReplicas.contains)
      if (leaderOpt.isDefined)
        controllerContext.stats.uncleanLeaderElectionRate.mark()
      leaderOpt
    } else {
      None
    }
  }
}
```

算法主要分两步：

* 1、遍历分区所有副本(分区AR集合)**顺序查找第一个在线且存在于ISR集合中的副本**，若存在，则该副本当选为当前分区的Leader副本。分区的AR集合顺序创建时确定，且只要不发生重分配，顺序不会改变；
* 2、上一步未选出Leader，分区所有在线副本均不在ISR副本中，判断分区所属的Topic是否允许非ISR副本当选为Leader(uncleanLeaderElectionEnabled)，即配置**unclean.leader.election.enable**是否为true(默认false)。若允许，则从**AR副本中查找第一onlineReplica即为Leader**。


### ReassignPartitionLeaderElectionStrategy

分区进行重分配后，会触发分区Leader的重新选举，此时选用的策略为ReassignPartitionLeaderElectionStrategy。对应算法实现如下：

```
def reassignPartitionLeaderElection(reassignment: Seq[Int], isr: Seq[Int], liveReplicas: Set[Int]): Option[Int] = {
  //遍历AR 查找第一个在线且在ISR集合中的副本作为Leader
  reassignment.find(id => liveReplicas.contains(id) && isr.contains(id))
}
```

算法比较简单，即选取AR集合中第一个在线且在ISR集合中的副本作为Leader。

### PreferredReplicaPartitionLeaderElectionStrategy


PreferredReplicaPartitionLeaderElectionStrategy代表进行**优先副本选举**。当Kafka集群中的Broker节点没有机架信息(broker.rack)时，分区中只有Leader副本负责对外提供读写服务，follower副本
只负责在内部进行消息同步。创建Topic时，Kafka会将Topic的所有分区及副本尽可能均匀的分布到集群中所有的Broker上，相应的各分区Leader副本(初始化为分区的第一个副本)的分配也比较均匀。
但随着出现Broker节点的宕机或崩溃，则会出现原先的follower副本成为leader副本的情况，**此时若一个Broker节点上的分区Leader副本过多，则可能导致Kafka集群的负载失衡**，Kafka为了有效治理负载失衡的情况，
引入了**优先副本(PreferredReplica)** 的概念。

优先副本(PreferredReplica)是指分区AR集合中的第一个副本。Kafka只要保证所有分区的优先副本在集群中均匀分布(Replica分配算法)，通过优先副本选举，则可以保证分区Leader副本的均匀分布，以此来促进
集群的负载均衡，也可以称为“分区平衡”。

* 分区平衡并不意味着Kafka集群的负载均衡，如所有主题分区分配是否均衡以及不同分区Leader副本的负载也不同。


优先副本选举算法实现如下：

```
def preferredReplicaPartitionLeaderElection(assignment: Seq[Int], isr: Seq[Int], liveReplicas: Set[Int]): Option[Int] = {
  assignment.headOption.filter(id => liveReplicas.contains(id) && isr.contains(id))
}
```

判断分区AR集合中的第一个副本是否在线且在ISR集合中，若满足，则当选为Leader副本。


### ControlledShutdownPartitionLeaderElectionStrategy

当Controller对应Broker节点关机时，会选用ControlledShutdownPartitionLeaderElectionStrategy为分区leader副本在本Broker节点的分区进行一次Leader副本的重新选举。算法如下：

```
def controlledShutdownPartitionLeaderElection(assignment: Seq[Int], isr: Seq[Int], liveReplicas: Set[Int], shuttingDownBrokers: Set[Int]): Option[Int] = {
  //遍历AR 查找第一个 在线  且 在ISR集合中 且  副本不在本Broker节点上 的副本作为Leader
  assignment.find(id => liveReplicas.contains(id) && isr.contains(id) && !shuttingDownBrokers.contains(id))
}
```

基于ControlledShutdownPartitionLeaderElectionStrategy策略选举出的Leader节点需满足3个条件：副本在线 & 副本在ISR集合中 & 副本不在本Broker节点上。